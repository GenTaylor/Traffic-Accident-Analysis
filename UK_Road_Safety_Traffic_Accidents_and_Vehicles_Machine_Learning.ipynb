{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## UK Road Safety: Traffic Accidents and Vehicles Machine Learning\n",
    " \n",
    " The goal of this project is the investigate what causes Serious and Fatal accidents in hopes of preventing and decreasing the number of them. The dataset consists of accident records from the UK over the course of 15+ years. I hope to show the causes of these accidents through visualizations and create an algorithm that can predict the severity of accidents. \n",
    " \n",
    "The UK government collects and publishes (usually on an annual basis) detailed information about traffic accidents across the country. This information includes, but is not limited to, geographical locations, weather conditions, type of vehicles, number of casualties and vehicle manoeuvres, making this a very interesting and comprehensive dataset for analysis and research.\n",
    "\n",
    "The data that I'm using is compiled and available through [Kaggle](https://www.kaggle.com/tsiaras/uk-road-safety-accidents-and-vehicles) and in a less compliled form, [here](https://beta.ukdataservice.ac.uk/datacatalogue/series/series?id=2000045). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Severe and fatal accidents.\n",
    "Solution: Use data to figure out how to lower the number of accidents and the severity of them.\n",
    "\n",
    "Questions:\n",
    "1. What effects the severity of accidents?\n",
    "2. What measures should be looked into in order to lessen the severity of accidents?\n",
    "3. Can we create an algorithm that correctly predicts the severity of accidents?\n",
    "4. What are the limitations of the current data?\n",
    "5. What things would help this research to be more accurate?\n",
    "6. Who does this project benefit?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "[Machine Learning](#Machine-Learning)<br>\n",
    "[Selected Machine Learning Algorithm and Explanation](#Selected-Machine-Learning-Algorithm-and-Explanation)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links to Other Notebooks\n",
    "__[UK Road Safety: Traffic Accidents and Vehicles Introduction, Data Cleaning, and Feature Manipulation](UK_Road_Safety_Traffic_Accidents_and_Vehicles_Data_Cleaning_and_Feature_Manipulation.ipynb)__<br>\n",
    "__[UK Road Safety: Traffic Accidents and Vehicles Introduction, Data Cleaning, and Feature Manipulation: Github Link](https://github.com/GenTaylor/Traffic-Accident-Analysis/blob/master/UK_Road_Safety_Traffic_Accidents_and_Vehicles_Data_Cleaning_and_Feature_Manipulation.ipynb)__<br>\n",
    "<br>\n",
    "\n",
    "__[UK Road Safety: Traffic Accidents and Vehicles Visualizations and Solution](UK_Road_Safety_Traffic_Accidents_and_Vehicles_Visualizations_and_Solution.ipynb)__<br>\n",
    "__[UK Road Safety: Traffic Accidents and Vehicles Visualizations and Solution: Github Link](https://github.com/GenTaylor/Traffic-Accident-Analysis/blob/master/UK_Road_Safety_Traffic_Accidents_and_Vehicles_Visualizations_and_Solution.ipynb)__<br>\n",
    "<br>\n",
    "__[UK Road Safety: Traffic Accidents and Vehicles Machine Learning](UK_Road_Safety_Traffic_Accidents_and_Vehicles_Machine_Learning.ipynb)__<br>\n",
    "__[UK Road Safety: Traffic Accidents and Vehicles Machine Learning: Github Link](https://github.com/GenTaylor/Traffic-Accident-Analysis/blob/master/UK_Road_Safety_Traffic_Accidents_and_Vehicles_Machine_Learning.ipynb)__<br>\n",
    "<br>\n",
    "__[Traffic Analysis and Severity Prediction Powerpoint Presentation](\"Traffic_Analysis_and_Severity_Prediction.pptx\")__<br>\n",
    "__[Traffic Analysis and Severity Prediction Powerpoint Presentation: Github Link](https://github.com/GenTaylor/Traffic-Accident-Analysis/blob/master/Traffic_Analysis_and_Severity_Prediction.pptx)__<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "#scipy\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "#sklearn\n",
    "import sklearn\n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#other learners\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "#time series stuff\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "import itertools\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "#warning ignorer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATAFRAME PICKLE CREATED IN CELLS BELOW INSTEAD OF RUNNING THROUGH ENTIRE PROCESS AFTER RESTARTING\n",
    "#import pickled file\n",
    "df = pd.read_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st_road_class</th>\n",
       "      <th>1st_road_number</th>\n",
       "      <th>2nd_road_number</th>\n",
       "      <th>accident_severity</th>\n",
       "      <th>carriageway_hazards</th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>did_police_officer_attend_scene_of_accident</th>\n",
       "      <th>junction_control</th>\n",
       "      <th>junction_detail</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>was_vehicle_left_hand_drive</th>\n",
       "      <th>x1st_point_of_impact</th>\n",
       "      <th>month</th>\n",
       "      <th>weekend</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>season</th>\n",
       "      <th>engine_capacity_cc_size</th>\n",
       "      <th>accident_seriousness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accident_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201001BS70003</th>\n",
       "      <td>B</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>Slight</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>Give way or uncontrolled</td>\n",
       "      <td>T or staggered junction</td>\n",
       "      <td>...</td>\n",
       "      <td>Goods Vehicle</td>\n",
       "      <td>No</td>\n",
       "      <td>Front</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>small engine cc</td>\n",
       "      <td>Not Serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001BS70004</th>\n",
       "      <td>A</td>\n",
       "      <td>402</td>\n",
       "      <td>4204</td>\n",
       "      <td>Slight</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>Auto traffic signal</td>\n",
       "      <td>T or staggered junction</td>\n",
       "      <td>...</td>\n",
       "      <td>Car</td>\n",
       "      <td>No</td>\n",
       "      <td>Front</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>winter</td>\n",
       "      <td>medium engine cc</td>\n",
       "      <td>Not Serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001BS70007</th>\n",
       "      <td>Unclassified</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Slight</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>Give way or uncontrolled</td>\n",
       "      <td>Mini-roundabout</td>\n",
       "      <td>...</td>\n",
       "      <td>Car</td>\n",
       "      <td>No</td>\n",
       "      <td>Nearside</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>winter</td>\n",
       "      <td>medium engine cc</td>\n",
       "      <td>Not Serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001BS70007</th>\n",
       "      <td>Unclassified</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Slight</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>Give way or uncontrolled</td>\n",
       "      <td>Mini-roundabout</td>\n",
       "      <td>...</td>\n",
       "      <td>Car</td>\n",
       "      <td>No</td>\n",
       "      <td>Front</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>winter</td>\n",
       "      <td>small engine cc</td>\n",
       "      <td>Not Serious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201001BS70008</th>\n",
       "      <td>A</td>\n",
       "      <td>3217</td>\n",
       "      <td>3220</td>\n",
       "      <td>Slight</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>Auto traffic signal</td>\n",
       "      <td>Crossroads</td>\n",
       "      <td>...</td>\n",
       "      <td>Car</td>\n",
       "      <td>No</td>\n",
       "      <td>Nearside</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>winter</td>\n",
       "      <td>medium engine cc</td>\n",
       "      <td>Not Serious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1st_road_class 1st_road_number 2nd_road_number  \\\n",
       "accident_index                                                  \n",
       "201001BS70003               B             302               0   \n",
       "201001BS70004               A             402            4204   \n",
       "201001BS70007    Unclassified               0               0   \n",
       "201001BS70007    Unclassified               0               0   \n",
       "201001BS70008               A            3217            3220   \n",
       "\n",
       "               accident_severity carriageway_hazards       date day_of_week  \\\n",
       "accident_index                                                                \n",
       "201001BS70003             Slight                None 2010-01-11      Monday   \n",
       "201001BS70004             Slight                None 2010-01-11      Monday   \n",
       "201001BS70007             Slight                None 2010-01-02    Saturday   \n",
       "201001BS70007             Slight                None 2010-01-02    Saturday   \n",
       "201001BS70008             Slight                None 2010-01-04      Monday   \n",
       "\n",
       "               did_police_officer_attend_scene_of_accident  \\\n",
       "accident_index                                               \n",
       "201001BS70003                                            1   \n",
       "201001BS70004                                            1   \n",
       "201001BS70007                                            1   \n",
       "201001BS70007                                            1   \n",
       "201001BS70008                                            1   \n",
       "\n",
       "                        junction_control          junction_detail  ...  \\\n",
       "accident_index                                                     ...   \n",
       "201001BS70003   Give way or uncontrolled  T or staggered junction  ...   \n",
       "201001BS70004        Auto traffic signal  T or staggered junction  ...   \n",
       "201001BS70007   Give way or uncontrolled          Mini-roundabout  ...   \n",
       "201001BS70007   Give way or uncontrolled          Mini-roundabout  ...   \n",
       "201001BS70008        Auto traffic signal               Crossroads  ...   \n",
       "\n",
       "                 vehicle_type was_vehicle_left_hand_drive  \\\n",
       "accident_index                                              \n",
       "201001BS70003   Goods Vehicle                          No   \n",
       "201001BS70004             Car                          No   \n",
       "201001BS70007             Car                          No   \n",
       "201001BS70007             Car                          No   \n",
       "201001BS70008             Car                          No   \n",
       "\n",
       "               x1st_point_of_impact month  weekend hour time_of_day  season  \\\n",
       "accident_index                                                                \n",
       "201001BS70003                 Front     1        0    7           1  winter   \n",
       "201001BS70004                 Front     1        0   18           6  winter   \n",
       "201001BS70007              Nearside     1        1   21           6  winter   \n",
       "201001BS70007                 Front     1        1   21           6  winter   \n",
       "201001BS70008              Nearside     1        0   20           6  winter   \n",
       "\n",
       "               engine_capacity_cc_size accident_seriousness  \n",
       "accident_index                                               \n",
       "201001BS70003          small engine cc          Not Serious  \n",
       "201001BS70004         medium engine cc          Not Serious  \n",
       "201001BS70007         medium engine cc          Not Serious  \n",
       "201001BS70007          small engine cc          Not Serious  \n",
       "201001BS70008         medium engine cc          Not Serious  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#made separate dataframe w. set index that wouldnt effect data vis above\n",
    "df1=df\n",
    "#set index to accident_index\n",
    "df1.set_index('accident_index', inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling\n",
    "Undersampling is done because of the extreme unevenness and bias of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First set up of X and Y\n",
    "X= df1.drop(['accident_severity','accident_seriousness'],axis=1)\n",
    "y= df1['accident_seriousness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "not_severe = X[X.accident_seriousness==0]\n",
    "severe = X[X.accident_seriousness==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease majority\n",
    "not_severe_decreased = resample(not_severe,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(severe), # match number in majority class\n",
    "                          random_state=27) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine majority and severe_increased minority\n",
    "newdf = pd.concat([severe, not_severe_decreased])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    51357\n",
       "0    51357\n",
       "Name: accident_seriousness, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.accident_seriousness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = newdf.drop('accident_seriousness', axis=1)\n",
    "y_train = newdf.accident_seriousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy Score: 57.68%\n",
      "Decision Tree Classifier F1 Score: 48.05%\n",
      "Decision Tree Classifier Precision Score: 53.81%\n",
      "Decision Tree Classifier Recall Score: 58.87%\n",
      "Decision Tree  Classifier Cross Validation Score: 60.69%\n",
      "\n",
      "\n",
      "Decision Tree Classifier Confusion Matrix:\n",
      " [[70663 52647]\n",
      " [ 6716 10258]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "pred_dtc = dtc.predict(X_test)\n",
    "\n",
    "#Check accuracy\n",
    "\n",
    "print(\"Decision Tree Classifier Accuracy Score: {:0.2f}%\".format(accuracy_score(y_test,\n",
    "                                                                               pred_dtc )*100))\n",
    "print(\"Decision Tree Classifier F1 Score: {:0.2f}%\".format(f1_score(y_test,\n",
    "                                                                   pred_dtc,average=\"macro\")*100))\n",
    "print(\"Decision Tree Classifier Precision Score: {:0.2f}%\".format(precision_score(y_test,\n",
    "                                                                                 pred_dtc, \n",
    "                                                                                 average=\"macro\")*100))\n",
    "print(\"Decision Tree Classifier Recall Score: {:0.2f}%\".format(recall_score(y_test, \n",
    "                                                                           pred_dtc,\n",
    "                                                                           average=\"macro\")*100))\n",
    "print(\"Decision Tree  Classifier Cross Validation Score: {:0.2f}%\".format(np.mean(cross_val_score(dtc, \n",
    "                                                                           X_train,\n",
    "                                                                           y_train,\n",
    "                                                                           cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Decision Tree Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy Score: 68.61%\n",
      "Bagging Classifier F1 Score: 55.35%\n",
      "Bagging Classifier Precision Score: 56.78%\n",
      "Bagging Classifier Recall Score: 64.18%\n",
      "Bagging Classifier Cross Validation Score: 65.24%\n",
      "\n",
      "\n",
      "Bagging Classifier Confusion Matrix:\n",
      " [[86343 36967]\n",
      " [ 7072  9902]]\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifier\n",
    "bagc = BaggingClassifier(random_state=42)\n",
    "\n",
    "bagc.fit(X_train, y_train)\n",
    "pred_bagc = bagc.predict(X_test)\n",
    "\n",
    "\n",
    "#Check accuracy\n",
    "\n",
    "print(\"Bagging Classifier Accuracy Score: {:0.2f}%\".format(accuracy_score(y_test,\n",
    "                                                                               pred_bagc )*100))\n",
    "print(\"Bagging Classifier F1 Score: {:0.2f}%\".format(f1_score(y_test,\n",
    "                                                                   pred_bagc,average=\"macro\")*100))\n",
    "print(\"Bagging Classifier Precision Score: {:0.2f}%\".format(precision_score(y_test,\n",
    "                                                                                 pred_bagc, \n",
    "                                                                                 average=\"macro\")*100))\n",
    "print(\"Bagging Classifier Recall Score: {:0.2f}%\".format(recall_score(y_test, \n",
    "                                                                           pred_bagc,\n",
    "                                                                           average=\"macro\")*100))\n",
    "print(\"Bagging Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(bagc, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Bagging Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_bagc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier Accuracy Score: 67.05%\n",
      "Extra Trees Classifier F1 Score: 53.95%\n",
      "Extra Trees Classifier Precision Score: 55.92%\n",
      "Extra Trees Classifier Recall Score: 62.58%\n",
      "Extra Trees Classifier Cross Validation Score: 64.16%\n",
      "\n",
      "\n",
      "Extra Trees Classifier Confusion Matrix:\n",
      " [[84446 38864]\n",
      " [ 7354  9620]]\n"
     ]
    }
   ],
   "source": [
    "#ExtraTreesClassifier\n",
    "\n",
    "extc = ExtraTreesClassifier(random_state=42)\n",
    "extc.fit(X_train, y_train)\n",
    "pred_extc = extc.predict(X_test)\n",
    "\n",
    "#Check accuracy\n",
    "\n",
    "print(\"Extra Trees Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_extc )*100))\n",
    "print(\"Extra Trees Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_extc,average=\"macro\")*100))\n",
    "print(\"Extra Trees Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_extc, average=\"macro\")*100))\n",
    "print(\"Extra Trees Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_extc, average=\"macro\")*100))\n",
    "print(\"Extra Trees Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(extc, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Extra Trees Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_extc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy Score: 66.56%\n",
      "AdaBoost Classifier F1 Score: 54.87%\n",
      "AdaBoost Classifier Precision Score: 57.20%\n",
      "AdaBoost Classifier Recall Score: 65.78%\n",
      "AdaBoost Classifier Cross Validation Score: 65.87%\n",
      "\n",
      "\n",
      "AdaBoost Classifier Confusion Matrix:\n",
      " [[82388 40922]\n",
      " [ 5985 10989]]\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost Classifier \n",
    "\n",
    "adbc = AdaBoostClassifier(random_state=42)\n",
    "adbc.fit(X_train, y_train)\n",
    "pred_adbc = adbc.predict(X_test)\n",
    "\n",
    "#Check accuracy\n",
    "\n",
    "#Check accuracy\n",
    "\n",
    "print(\"AdaBoost Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_adbc )*100))\n",
    "print(\"AdaBoost Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_adbc,average=\"macro\")*100))\n",
    "print(\"AdaBoost Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_adbc, average=\"macro\")*100))\n",
    "print(\"AdaBoost Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_adbc, average=\"macro\")*100))\n",
    "print(\"AdaBoost Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(adbc, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"AdaBoost Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_adbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy Score: 68.44%\n",
      "Random Forest Classifier F1 Score: 54.92%\n",
      "Random Forest Classifier Precision Score: 56.38%\n",
      "Random Forest Classifier Recall Score: 63.29%\n",
      "Random Forest Classifier Cross Validation Score: 64.76%\n",
      "\n",
      "\n",
      "Random Forest Classifier Confusion Matrix:\n",
      " [[86420 36890]\n",
      " [ 7384  9590]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 42)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "#Check accuracy\n",
    "print(\"Random Forest Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_rfc )*100))\n",
    "print(\"Random Forest Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_rfc,average=\"macro\")*100))\n",
    "print(\"Random Forest Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_rfc, average=\"macro\")*100))\n",
    "print(\"Random Forest Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_rfc, average=\"macro\")*100))\n",
    "print(\"Random Forest Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(rfc, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Random Forest Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_rfc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy Score: 68.21%\n",
      "Gradient Boosting Classifier F1 Score: 56.07%\n",
      "Gradient Boosting Classifier Precision Score: 57.75%\n",
      "Gradient Boosting Classifier Recall Score: 66.65%\n",
      "Gradient Boosting Classifier Cross Validation Score: 66.77%\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier Confusion Matrix:\n",
      " [[84729 38581]\n",
      " [ 6010 10964]]\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "gbc = ensemble.GradientBoostingClassifier(random_state = 42)\n",
    "gbc.fit(X_train, y_train)\n",
    "pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Check accuracy\n",
    "print(\"Gradient Boosting Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_gbc )*100))\n",
    "print(\"Gradient Boosting Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_gbc,average=\"macro\")*100))\n",
    "print(\"Gradient Boosting Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_gbc, average=\"macro\")*100))\n",
    "print(\"Gradient Boosting Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_gbc, average=\"macro\")*100))\n",
    "print(\"Gradient Boosting Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(gbc, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Gradient Boosting Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier Accuracy Score: 67.56%\n",
      "LightGBM Classifier F1 Score: 56.08%\n",
      "LightGBM Classifier Precision Score: 58.10%\n",
      "LightGBM Classifier Recall Score: 67.71%\n",
      "LightGBM Classifier Cross Validation Score: 67.65%\n",
      "\n",
      "\n",
      "LightGBM Classifier Confusion Matrix:\n",
      " [[83256 40054]\n",
      " [ 5448 11526]]\n"
     ]
    }
   ],
   "source": [
    "#Light GBM\n",
    "lgbm = lgb.LGBMClassifier(random_state = 42)\n",
    "lgbm.fit(X_train, y_train)\n",
    "pred_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "#check accuracy\n",
    "print(\"LightGBM Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_lgbm )*100))\n",
    "print(\"LightGBM Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_lgbm,average=\"macro\")*100))\n",
    "print(\"LightGBM Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_lgbm, average=\"macro\")*100))\n",
    "print(\"LightGBM Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_lgbm, average=\"macro\")*100))\n",
    "print(\"LightGBM Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(lgbm, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"LightGBM Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy Score: 68.11%\n",
      "XGBoost Classifier F1 Score: 56.45%\n",
      "XGBoost Classifier Precision Score: 58.25%\n",
      "XGBoost Classifier Recall Score: 67.91%\n",
      "XGBoost Classifier Cross Validation Score: 68.74%\n",
      "\n",
      "\n",
      "XGBoost Classifier Confusion Matrix:\n",
      " [[84061 39249]\n",
      " [ 5490 11484]]\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "xgb = XGBClassifier(n_estimators=100, random_state = 42, max_depth=10)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "#check accuracy\n",
    "print(\"XGBoost Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_xgb)*100))\n",
    "print(\"XGBoost Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_xgb,average=\"macro\")*100))\n",
    "print(\"XGBoost Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_xgb, average=\"macro\")*100))\n",
    "print(\"XGBoost Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_xgb, average=\"macro\")*100))\n",
    "print(\"XGBoost Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(xgb, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"XGBoost Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RANDOM FOREST PARAM\n",
    "# rfc_param = {\n",
    "#     'n_estimators': [100, 200, 300, 500],\n",
    "#     'criterion': ['entropy', 'gini'],\n",
    "#     'max_features':['auto','sqrt'],\n",
    "#     'max_depth': [10, 50, 100],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4, 10],\n",
    "#     'random_state':[42]}\n",
    "\n",
    "# grid_rfc = GridSearchCV(rfc, param_grid = rfc_param, cv = 3, verbose = 1, n_jobs=-1)\n",
    "# grid_rfc.fit(X_train,y_train)\n",
    "\n",
    "# print(rfcbest_estimator = grid_rfc.best_estimator_)\n",
    "# print(\"Random Forest:\\n\",grid_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Gradient Boosting Classifier Tuning\n",
    "# gbcparam= {'learning_rate':[0.5,0.1,1],\n",
    "#            'n_estimators': [100, 200, 300, 500],\n",
    "#            'max_features':['auto','sqrt'],\n",
    "#            'max_depth': [10, 50, 100],\n",
    "#            'min_samples_leaf': [1, 2, 4, 10],\n",
    "#            'min_samples_split': [2, 5, 10],\n",
    "#            'random_state':[42]}\n",
    "\n",
    "\n",
    "\n",
    "# gbctuning =GridSearchCV(gbc, param_grid = gbcparam, cv = 3, verbose = 1, n_jobs=-1)\n",
    "\n",
    "\n",
    "# gbctuning.fit(X_train,y_train)\n",
    "                      \n",
    "# print(\"Gradient Boost:\\n\",gbctuning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1296 out of 1296 | elapsed: 88.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM:\n",
      " {'learning_rate': 0.1, 'max_depth': 25, 'min_data_in_leaf': 100, 'n_estimators': 500, 'num_leaves': 50, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "# #LightGBM Tuning\n",
    "\n",
    "# lgbmparam={'learning_rate':[0.5,0.1,1],\n",
    "#            'n_estimators': [100, 200, 300, 500],\n",
    "#            'max_depth': [6, 25, 50,100],\n",
    "#            \"num_leaves\": [6,12,50],\n",
    "#            'min_data_in_leaf' : [100,500,1000],\n",
    "#            'random_state':[42]}\n",
    "\n",
    "# lgbmtuning =GridSearchCV(lgbm, param_grid = lgbmparam, cv = 3, n_jobs=1, verbose = 1)\n",
    "\n",
    "\n",
    "# lgbmtuning.fit(X_train,y_train)\n",
    "                     \n",
    "# print(\"LightGBM:\\n\",lgbmtuning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #XGBoost Tuning\n",
    "# xgbparam ={'max_depth': [10, 50, 100],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy Score: 67.08%\n",
      "Random Forest Classifier F1 Score: 55.98%\n",
      "Random Forest Classifier Precision Score: 58.25%\n",
      "Random Forest Classifier Recall Score: 68.21%\n",
      "Random Forest Classifier Cross Validation Score: 69.58%\n",
      "\n",
      "\n",
      "Random Forest Classifier Confusion Matrix:\n",
      " [[82271 41039]\n",
      " [ 5143 11831]]\n",
      "Random Forest Time:  1006.990118265152\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rfc2 = RandomForestClassifier(criterion='entropy', max_depth=40, \n",
    "                              max_features='sqrt', min_samples_split=8, \n",
    "                              n_estimators=500, random_state=42)\n",
    "rfc2.fit(X_train, y_train)\n",
    "pred_rfc2 = rfc2.predict(X_test)\n",
    "#Check accuracy\n",
    "\n",
    "\n",
    "#Check accuracy\n",
    "print(\"Random Forest Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_rfc2 )*100))\n",
    "print(\"Random Forest Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_rfc2,average=\"macro\")*100))\n",
    "print(\"Random Forest Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_rfc2, average=\"macro\")*100))\n",
    "print(\"Random Forest Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_rfc2, average=\"macro\")*100))\n",
    "print(\"Random Forest Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(rfc2, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Random Forest Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_rfc2))\n",
    "end = time.time()\n",
    "print(\"Random Forest Time: \",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "start2 = time.time()\n",
    "gbc2 = ensemble.GradientBoostingClassifier(learning_rate=0.05, max_depth=40, \n",
    "                                           min_samples_leaf=1, n_estimators=500,\n",
    "                                           random_state = 42)\n",
    "gbc2.fit(X_train, y_train)\n",
    "pred_gbc2 = gbc2.predict(X_test)\n",
    "\n",
    "#Check accuracy\n",
    "print(\"Gradient Boosting Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_gbc2 )*100))\n",
    "print(\"Gradient Boosting Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_gbc2,average=\"macro\")*100))\n",
    "print(\"Gradient Boosting Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_gbc2, average=\"macro\")*100))\n",
    "print(\"Gradient Boosting Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_gbc2, average=\"macro\")*100))\n",
    "print(\"Gradient Boosting Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(gbc2, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"Gradient Boosting Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_gbc2))\n",
    "end2 = time.time()\n",
    "print(\"Gradient Boosting Time:\", end2 - start2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier Accuracy Score: 67.93%\n",
      "LightGBM Classifier F1 Score: 56.41%\n",
      "LightGBM Classifier Precision Score: 58.29%\n",
      "LightGBM Classifier Recall Score: 68.06%\n",
      "LightGBM Classifier Cross Validation Score: 68.22%\n",
      "\n",
      "\n",
      "LightGBM Classifier Confusion Matrix:\n",
      " [[83719 39591]\n",
      " [ 5392 11582]]\n",
      "LightGBM Time: 73.5155577659607\n"
     ]
    }
   ],
   "source": [
    "#Light GBM\n",
    "#LightGBM:{'learning_rate': 0.1, 'max_depth': 25, 'min_data_in_leaf': 100, \n",
    "#'n_estimators': 500, 'num_leaves': 50, 'random_state': 42}\n",
    "start3 = time.time()\n",
    "lgbm2 = lgb.LGBMClassifier(learning_rate =0.03, max_depth=40, min_data_in_leaf=10, \n",
    "                           max_cat_threshold=99999999,\n",
    "                           n_estimators=500, num_leaves=50, random_state = 42)\n",
    "lgbm2.fit(X_train, y_train)\n",
    "pred_lgbm2 = lgbm2.predict(X_test)\n",
    "\n",
    "#check accuracy\n",
    "print(\"LightGBM Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_lgbm2 )*100))\n",
    "print(\"LightGBM Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_lgbm2,average=\"macro\")*100))\n",
    "print(\"LightGBM Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_lgbm2, average=\"macro\")*100))\n",
    "print(\"LightGBM Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_lgbm2, average=\"macro\")*100))\n",
    "print(\"LightGBM Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(lgbm2, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"LightGBM Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_lgbm2))\n",
    "end3 = time.time()\n",
    "print(\"LightGBM Time:\", end3 - start3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy Score: 66.69%\n",
      "XGBoost Classifier F1 Score: 55.71%\n",
      "XGBoost Classifier Precision Score: 58.13%\n",
      "XGBoost Classifier Recall Score: 68.04%\n",
      "XGBoost Classifier Cross Validation Score: 69.27%\n",
      "\n",
      "\n",
      "XGBoost Classifier Confusion Matrix:\n",
      " [[81700 41610]\n",
      " [ 5123 11851]]\n",
      "XGBoost Time: 7625.058862447739\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "start4 = time.time()\n",
    "xgb2 = XGBClassifier(learning_rate=0.05, n_estimators=500, subsample= 1,random_state = 42,\n",
    "                     gamma = 1, max_depth=40)\n",
    "xgb2.fit(X_train, y_train)\n",
    "\n",
    "pred_xgb2 = xgb2.predict(X_test)\n",
    "\n",
    "#check accuracy\n",
    "print(\"XGBoost Classifier Accuracy Score: {:0.2f}%\"\n",
    "      .format(accuracy_score(y_test,pred_xgb2)*100))\n",
    "print(\"XGBoost Classifier F1 Score: {:0.2f}%\"\n",
    "      .format(f1_score(y_test, pred_xgb2,average=\"macro\")*100))\n",
    "print(\"XGBoost Classifier Precision Score: {:0.2f}%\"\n",
    "      .format(precision_score(y_test, pred_xgb2, average=\"macro\")*100))\n",
    "print(\"XGBoost Classifier Recall Score: {:0.2f}%\"\n",
    "      .format(recall_score(y_test, pred_xgb2, average=\"macro\")*100))\n",
    "print(\"XGBoost Classifier Cross Validation Score: {:0.2f}%\"\n",
    "      .format(np.mean(cross_val_score(xgb2, X_train, y_train, cv=5)*100)))\n",
    "print('\\n')\n",
    "print(\"XGBoost Classifier Confusion Matrix:\\n\", confusion_matrix(y_test,pred_xgb2))\n",
    "end4 = time.time()\n",
    "print(\"XGBoost Time:\", end4 - start4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected Machine Learning Algorithm and Explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
